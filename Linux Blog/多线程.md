# 多线程

### Linux线程概念

##### 什么是线程

> * 在一个程序里的一个执行路线就叫做线程（thread）。更准确的定义是：线程是“一个进程内部的控制序列”
> * 一切进程至少都有一个执行线程
> * 线程在进程内部运行，本质是在进程地址空间内运行
> * 在Linux系统中，在CPU眼中，看到的PCB都要比传统的进程更加轻量化
> * 通过进程虚拟地址空间，可以看到进程的大部分资源，将进程资源合理分配给每个执行流，就形成了流程执行流
> * 线程是运行在进程之中的，进程负责资源的管理（管理内存，管理打开的文件），线程负责调度和执行（和进程类型，也是抢占式的调度）
> * Linux也把线程叫做轻量级进程（LWP）

##### 线程的优点

> * 创建/销毁一个新线程的代价要比创建/销毁一个新进程小得多
> * 每次创建一个新的进程，会分配新的虚拟地址空间，每次创建一个新的线程，线程共用原来的虚拟地址空间
> * 与进程之间的切换相比，线程之间的切换需要操作系统做的工作要少很多
> * 线程占用的资源要比进程少很多
> * 能充分利用多处理器的可并行数量
> * 在等待慢速I/O操作结束的同时，程序可执行其他的计算任务
> * 计算密集型应用，为了能在多处理器系统上运行，将计算分解到多个线程中实现
> * I/O密集型应用，为了提高性能，将I/O操作重叠。线程可以同时等待不同的I/O操作

##### 线程的缺点

> * 性能损失
>   * 一个很少被外部事件阻塞的计算密集型线程往往无法与其他线程共享同一个处理器。如果计算密集型线程数量比可用的处理器多，那么可能会有较大的性能损失，这里的性能损失指的是增加了额外的同步和调度开销，而可用的资源不变
> * 健壮性降低
>   * 一个线程异常终止会导致进程异常终止
> * 编程/调试难度提高
>   * 对线程的可靠性要求更高
>   * 线程安全问题

##### 多线程/多进程的应用场景

> * CPU（计算）密集型
> * I/O密集型
>   * 通过网络进行输入输出
>   * 响应UI界面（界面显示和数据计算要多线程完成，防止由于计算太久导致界面卡死）

##### 线程之间共用的资源

> * 虚拟地址空间
> * 文件描述符表
> * 等等

##### 线程之间不共用的资源

> * 栈（函数调用栈，局部变量等）
> * 上下文信息（寄存器信息）
> * errno（每个线程有自己的错误码）
>   * thread local

##### 线程问题

> 线程不是越多越好，达到一定数目的时候效率就没法提升了
>
> 线程如果多了，多个线程尝试访问同一个资源，就会冲突（互斥解决）
>
> 某个线程可能一直得不到执行的机会，线程饥饿（同步）
>
> 如果某个进程异常终止，整个进程都异常终止

### 线程控制

##### POSIX线程库

> * 与线程有关的函数构成了一个完整的系列，绝大多数的名字都是以"pthread_"开头的
> * 要使用这些函数库，要引入头文件<pthread.h>,pthread中的p代表posix
> * 连接这些线程函数库时要使用编译器命令的"-lpthread"选项
>   * gcc的-l表示链接一个库，直接写库名，不用包含前缀lib或后缀.so
>
> C++11/Java/Python...各种语言都内置了线程库

##### 创建线程

**ps -eLf 查看所有的线程信息(LWP表示线程ID),站在内核角度给PCB加的编码**

**pthread_self得到的线程id是站在posix线程库的角度**

**pstack PID查看指定进程中的线程信息**

**gdb attach PID**

**info thread查看线程**

**thread n切换到n号线程**

**bt查看当前线程的调用栈**

```
功能：创建一个新的线程
原型
	int pthread_create(pthread_t *thread,const pthread_attr_t *attr, void *(*start_routine)(void*), void *arg);
参数
	thread：返回线程ID
	attr：设置线程的属性，attr为NULL表示使用默认属性
	start_routine:是个函数地址，线程启动后要执行的函数，相当于新线程的入口函数
	arg：传给线程启动函数的参数
返回值：成功返回0；失败返回错误码
```

错误检查：

> * 传统的一些函数是，成功返回0，失败返回-1，并且对全局变量errno赋值以指示错误
> * pthreads函数出错时不会设置全局变量errno（而大部分其他POSIX函数会这样做）。而是将错误代码通过返回值返回

**线程是抢占式执行的，当前哪个线程去执行，哪个线程去休眠，这件事件都不是程序员能决定的，全靠操作系统来决定**

**这就是多线程编程中的“万恶之源”**

##### 终止线程

> * 让线程入口函数执行结束（最主要使用的结束方式）
> * pthread_exit 让线程终止自己，pthread_exit的参数是一个void*表示线程结束的返回结果（很少用到）
> * 一个线程可以调用pthread_cancel终止同一进程中的另一个线程，参数为LWP,虽然有延迟处理，延迟到进程停止状态，但还是有可能会导致另一个线程的事务中断，（不太推荐使用）

##### 等待进程

> 目的和进程等待类似，防止出现类似与僵尸进程的内存泄露的情况,其实是为了等待对应线程结束后再继续执行代码，保持代码运行逻辑性
>
> * pthread_join
>
> ```
> 功能：等待指定线程结束
>  int pthread_joid(pthread_t thread, void **value_ptr);
>  参数
>  	thread：线程ID
>  	value_ptr：指向一个指针，或者指向线程的返回值
> 返回值：成功返回0，失败返回错误码
> ```

##### 线程分离

> 类似于进程中的 忽略SIGCHLD信号,线程被分离后，就不需要pthread_join来显式回收了
>
> * pthread_detach
>
> * ```
>   pthread_detach(pthread_t thread)//对其他线程分离
>   pthread_detach(pthread_self())//对自己分离
>   ```

到底搞几个线程合适？线程数目和工作的任务类型有关，究竟多少个合适，要通过测试来判定

### Linux线程互斥

##### 进程线程间的互斥相关背景概念

> * 临界资源：多线程执行流共享的资源就叫做临界资源
> * 临界区：每个线程内部，访问临界资源的代码，就叫做临界区
> * 互斥：任何时刻，互斥保证有且只有一个执行流进入临界区，访问临界资源，通常对临界资源起保护作用
> * 原子性：不会被任何调度机制打断的操作，该操作只有两态，要么完成，要么未完成

### 互斥量mutex

> * 大部分情况，线程使用的数据都是局部变量，变量的地址空间再线程栈空间内，这种情况，变量归属单个线程，其他线程无法获得这种变量
> * 但有时候，很多变量都需要在线程间共享，这样的变量称为共享变量，可以通过数据的共享，完成线程之间的交互
> * 多个线程并发的操作共享变量，会带来线程不安全的问题

以上问题就需要互斥锁/量=>类似于ATM门上的锁来解决

互斥锁pthread_mutex”挂起等待锁“，一旦线程获取锁失败，就会挂起（进入到操作系统提供的一个等待队列中），这个线程在其他线程释放锁之后，当前线程还得看操作系统的调度来决定啥时恢复执行

互斥机制的使用

> * 先加锁
> * 执行临界区代码
> * 释放锁

### 互斥量的接口

初始化互斥量

> * 方法一：静态分配

```
pthread_mutex_t mutex = PTHREAD_INITIALIZER
```

> * 方法二：动态分配

```
int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t 
*restrict attr);
参数：
	mutex：要初始化的互斥量
	attr：NULL
```

销毁互斥量  

```
int pthread_mutex_destroy(pthread_mutex_t *mutex)
```

互斥量加锁和解锁

```
int pthread_mutex_lock(pthread_mutex_t *mutex);
int pthread_mutex_unlock(pthread_mutex_t *mutex);
返回值：成功返回0，失败返回错误号
```

互斥锁能够保证线程安全，最终的程序效率会受到影响，除此之外，还有一个更严重的问题：死锁

##### 死锁的常见场景：

> * 一个线程加锁之后再次尝试加锁
> * 两个线程1,2,有两把锁A，B，线程1先去获取锁A，再去获取锁B，同时线程2先去获取锁B，再去获取锁A，也会死锁
> * 多个线程多把锁（哲学家就餐问题）

##### 避免死锁算法(哲学家吃鸡（每人旁边一支筷子）)：

> * 给每个筷子编号
>   * 约定哲学家每次先拿编号小的筷子
>   * 破除死锁“环路等待”
> * 信号量为筷子数-1，每次加锁，信号量-1（P操作），解锁（信号量+1）

##### 比较常用的死锁解决方案（从代码设计的角度来规避死锁问题）

> * 短	临界区代码尽量短
> * 平    临界区代码尽量避免复杂的函数调用
> * 快    临界区代码执行速度尽量块，别做太耗时的操作

### 可重入VS线程安全

##### 可重入函数：一个函数在任意的执行流中调用，都不会出问题

##### 线程安全函数：一个函数再任意的线程中调用，都不会出问题

**C++STL中所提供的容器和算法都是线程不安全的**

##### 可重入这个概念要求更高，涵盖了线程安全。

##### 一个函数可重入，一定线程安全；一个函数线程安全，不一定可重入。

##### 信号处理函数很少用到，因为一旦进入信号处理函数，原来的逻辑不管多少个线程都得停下来等待信号处理函数运行完

### Linux线程同步

##### 条件变量

> * 当一个线程互斥地访问某个变量时，它可能发现在其他线程改变状态之前，它什么也做不了
> * 例如一个线程访问队列时，发现队列为空，它只能等待，直到其他线程将一个节点添加到队列中。这种情况需要用到条件变量

##### 条件变量函数

初始化

```
int pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr);
参数：
	cond:要初始化的条件变量
	attr:NULL
```

销毁

```
int pthread_cond_destroy(pthread_cond_t *cond)
```

等待条件满足

```
int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex);
参数：
	cond:要在这个条件变量上等待
	mutex：互斥量，后面详细解释
```

唤醒等待

```
int pthread_cond_broadcast(pthread_cond_t *cond);
int pthread_cond_signal(pthread_cond_t *cond);
```

pthread_cond_wait做了一下：

> * 先释放锁
> * 等待条件就绪
>   * 前两个操作必须是原子的，否则可能会错过其他线程的通知消息，导致还在这傻等
> * 重新获取锁，准备执行后续的操作
>
> 必须搭配互斥锁来使用
>
> 大部分情况下，条件变量和互斥锁搭配使用

##### 同步概念

> * 同步：在保证数据安全的前提下，让线程能够按照某种特定的顺序访问临界资源，从而有效避免饥饿问题，叫做同步

### 生产者消费者模型

通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力，这个阻塞队列就是用来给生产者和消费者解耦的

消费者和消费者之间，互斥关系

生产者和生产者之间，互斥关系

生产者和消费者之间，互斥同步关系

通过互斥锁只是实现了生产者和消费者之间的互斥关系

使用同步进一步改进，如果vector中没有数据消费者就啥都不做

321原则：三种关系，两个角色，一个阻塞队列

##### 生产者消费者模式优点

> * 解耦
> * 支持并发
> * 支持忙闲不均

```
#include<stdio.h>
#include<vector>
#include<unistd.h>
#include<pthread.h>
//实现一个生产者消费者模型
//首先得有一个交易场所
std::vector<int> data;
//然后得有两个角色，（生产者和消费者）两个线程
void* Product(void* arg)
{
    (void) arg;
    while(1)
    {
        data.push_back(++count);
        usleep(789789);
    }
    return NULL;
}
void* Consume(void* arg)
{
    (void) arg;
    while(1)
    {
    	if(!data.empty()){
        	int result = data.back();
        	date.pop_back();
        	prinft("result = %d\n",result);
        	usleep(123123);
        }
    }
}
int main()
{
    pthread_t tid1,tid2;
    pthread_create(&tid1,NuLL,Product,NULL);
    pthread_create(&tid2,NuLL,Consume,NULL);
    pthread_join(tid1,NULL);
    pthread_join(tid2,NULL);
    return 0;
}
```

##### 阻塞队列：线程安全版本的队列

```
#pragma once
#include<vector>
#include<pthread.h>
#include<semaphore.h>

//一般BlockingQueue都要求长度是有上限的
//如果队列为空，去执行Pop就会阻塞
//如果队列满了，去执行Push也会阻塞
//信号量表示互斥比较简单，但是表示同步就比较复杂

//信号量表示可用资源的个数
//一个信号量表示当前队列中元素的个数
//另一个信号量表示当前队列中空格的个数
//插入元素就是在消耗一个空格资源，释放了一个元素资源
//删除元素就是在消耗一个元素资源，释放了一个空格资源
//如果用信号量表示互斥，P和V操作在同一个函数中
//如果用信号量表示同步，P和V操作不在一个函数中
template <class T>
class BlockingQueue
{
public:
	BlockingQueue(int max_size)
    	: max_size_(max_size),head_(0);tail_(0),size_(0),queue_(max_size)
	{
        sem_init(&lock_,0,1);
        sem_init(&elem_,0,1);
        sem_init(&blank_,0,1);
        
	}
	~BlockingQueue()
	{
        sem_destroy(&lock_);
        sem_destroy(&elem_);
        sem_destroy(&blank_);
        
	}
	void Push(const T& data)
	{
	//每次要插入元素，就得现申请一个空格资源
	//如果没有空格资源（信号量为0），说明队列满了
	//满了就不能继续插入，并在Push中阻塞
		sem_wait(&blank_);
	
		sem_wait(&lock_);//信号量这个计数器的+1 -1 是原子的
        queue_[tail_] = data;
        ++head+;
        ++size_;
        sem_post(&lock_);
        
        sem_post(&blank_);
	}
	void Pop(T* data)
	{
	//每次出队列。。。(对应Push)
		sem_wait(&elem_);
	
		sem_wait(&lock_);
        *data = queue_[head_];
        ++head_;
        --size_;
        sem_post(&lock_);
        
        sem_post(&elem_);
	}
	
private：
	std::vector<T> queue_;
	int head_;
	int tail_;
	int size_;
	int max_size_;
	sem_t lock;//用一个二元信号量（非0即1）表示互斥锁
	set_t elem_;//可用元素的个数
	set_t blank_;//可用空格的个数
};
```

### 线程池

创建线程的开销也不是完全可以忽略不计，线程池是一种线程使用模式，线程池维护多个线程

能够提前把线程创建好，避免频繁创建销毁线程的开销

线程不必依次创建太多，复用一个线程来完成多个任务

```
#pragma once
#include<stdio.h>
class Task{//用户可以从Task继承一个子类，自己通过多态实现自定制Run的逻辑
public:
	virtual void Run(){
        printf("base Run\n");
	}
	virtual ~Task(){}
};
//线程池对象启动的时候会创建一组线程
//每个线程都需要完成一定的任务（执行一定的代码逻辑，这个逻辑是由调用者来决定的）
//任务是一段代码，可以用函数来表示
class ThreadPool
{
public:
//n表示创建线程的数量
	ThreadPool(int n)
		:queue_(100),worker_count_(n)
	{
		//创建出n个线程
		for(int i =0;i<worker_count_;++i)
		{
            pthread_t tid;
            pthread_crease(&tid,NULL,ThreadEntry，this);
            workers_.push_back(tid);
		}
	}
	~ThreadPool(){
	//先让线程退出，然后再回收
        for(size_t i=0;i<workers_.size();++i){
        pthread_cancel（workers_[i]）; 
        }
        for(size_t i=0;i<workers_.size();++i)
        {
            pthread_join(workers_[i],NULL);
        }
	}
	//使用线程池的时候，就需要由调用者加入一些任务，让线程去执行
	void AddTask(Task* task)
	{
		queue_.Push(task);
	}
private:
	BlockingQueue<Task*> queue_;
	int worker_count_;
	vector<pthread_t> workers_;
	static void* ThreadEntry(void*)
	{
       	ThreadPool* pool = (ThreadPool*)arg;
       	while(true)
       	{
       	//循环中尝试从阻塞队列中获取任务，获取dao一个任务就执行一个任务
       	Task* task = NULL;
       	pool->queue.Pop(&task);
       	//task表面上看是一个Task* 类型，实际上指向的是用户定义的子类Task对象，执行子类的         //Run逻辑
       	task->Run();
       	delete task;
       	}
	}
}
```

